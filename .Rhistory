est-mu
est
sort(mu)
apply(mu, 2, sort)
est
est - est
length(est)
dim(mu)
mu
est - mu
apply(est - mu, 0.025, sort, quantile(q, names = FALSE))
help(apply)
apply(est - mu, 1, quantile(0.025, names = FALSE))
apply(est - mu, 2, function(x) quantile(x, 0.025, names = FALSE))
rm(list=ls())
source('~/Desktop/Fall 2020/Causal Inference/homework5/homework5.R')
est
f <- function(df) q_learning(df, x2, y2, x1, q_features, a2_features)
library(MASS)
# Input:
#   df: a data frame to be resampled.
#   k: number of resampled datasets to generate.
#   f: a function of df giving a vector of statistics of interest of size n.
#   q: a real number 0 < q < 0.5 giving the lower quantile of the desired
#   confidence interval.
# Output:
#   an n by four matrix where each row represents one of the parameters of
#   interest (first element), lower and upper confidence intervals around it,
#   corresponding to q and 1-q quantiles (second and third elements),
#   and the size of the confidence interval (fourth element).
bootstrap_vector_ci = function(df, k, f, q){
est <- f(df)
function_length <- length(est)
mu <- matrix(nrow = k, ncol = function_length)
for(i in 1:k){
df_r <- df_resample(df)
mu[i,] <- f(df_r)
}
mu <- apply(mu, 2, sort)
cbind(est, est + apply(est - mu, 2, function(x) quantile(x, q, names = FALSE)), est + apply(est - mu, 2, function(x) quantile(x, 1-q, names = FALSE)),
apply(est - mu, 2, function(x) quantile(x, 1-q, names = FALSE)) - apply(est - mu, 2, function(x) quantile(x, q, names = FALSE))
)
}
# Input:
#   df: a data frame.
#   x2: a set of column indices of size m representing features used for
#   the stage 2 regression model.
#   y2: a column index representing the outcome used for the stage 2
#   regression model.
#   x1: a set of column indices of size l representing feature used for the
#   stage 1 regression model.
#   q_features: indices in x2 used for predicting counterfactual reward
#   for a given trajectory under different assignments to stage 2 treatment.
#   a2_features: indices in x2 corresponding to columns which involve
#   stage 2 treatment.
# Output:
#   an (m+l) length vector, representing a concatenation of parameters of
#   the stage 2 model, followed by parameters of the stage 1 model.
q_learning = function(df, x2, y2, x1, q_features, a2_features){
stage_2_model <- linreg(as.matrix(df[,x2]), as.matrix(df[,y2]))
Q_2 <- rep(0, nrow(df))
for(i in 1:nrow(df)) {
row <- df[i,]
row_q_features <- row[q_features]
Y_a2_1 <- as.matrix(row_q_features) %*% t(stage_2_model)
Y_a2_minus_1 <- 0
if (row_q_features[a2_features[1]] == 1) {
row_q_features_shifted <- row_q_features
row_q_features_shifted[a2_features] <- row_q_features_shifted[a2_features] * (-1)
Y_a2_minus_1 <- as.matrix(row_q_features_shifted) %*% t(stage_2_model)
}
Q_2[i] <- max(Y_a2_1,Y_a2_minus_1)
}
stage_1_model <- linreg(as.matrix(df[,x1]), Q_2)
return(c(stage_2_model, stage_1_model))
}
# Input:
#          n: the number of samples to generate
# Output:  a data frame giving n data points sampled from a variant of the model given in Chapter 3 of
#          "Statistical Methods for Dynamic Treatment Regimes."
ch3_sim_study = function(n = 500){
eta0 <- -0.5
eta1 <- 0.5
eta2 <- 1   #variant
zeta0 <- -0.8
zeta1 <- 1.25
delta1 <- 0.1
delta2 <- 0.1
o1 <- sample(c(0,1), n, 0.5)
c1 <- rnorm(n, 0, 1)
p <- logis(zeta0 + zeta1 * c1)
a1 <- sapply(p, function(x) sample(c(-1,1), 1, x))
p <- logis(delta1 * o1 + delta2 * a1)
o2 <- sapply(p, function(x) sample(c(0,1), 1, x))
c2 <- rnorm(n, eta0 + eta1 * c1 + eta2 * o2, 1) #variant
p <- logis(zeta0 + zeta1 * c2)
a2 <- sapply(p, function(x) sample(c(-1,1), 1, x))
gamma1 <- 1
gamma5 <- 1
gamma <- c(0, gamma1, 0, -0.5, 0, gamma5, 0.25, 0.5, 0.5)
mu <- gamma[1] + gamma[2] * c1 + gamma[3] * o1 + gamma[4] * a1 + gamma[5] * o1 * a1 + gamma[6] * c2
+ gamma[7] * c2 + gamma[8] * o2 * a2 + gamma[8] * a1 * a2
y <- rnorm(n, mu, 1)
dat <- cbind(o1, c1, a1, o2, c2, a2, y)
df <- df_make(dat)
# add certain interaction columns
#
#           intercept               o1*a1            a1*a2            a2*o2
df <- cbind(rep(1, dim(df)[1]), df, df[,1] * df[,3], df[,3] * df[,6], df[,4] * df[,6])
}
# Input:
#           df: a data frame with n rows.
# Output:   a data frame with n rows obtained from the input dataframe by sampling rows with replacement.
df_resample = function(df){
nrows <- dim(df)[1]
index <- sample(1:nrows, nrows, replace = TRUE)
df[index,]
}
# Input:
#           mat: a data matrix with n rows and k columns (rows are samples, columns are variables).
# Output:   a data frame with column (variable) names "x1" to "xk", and data from the matrix.
df_make = function(mat){
df <- as.data.frame(mat)
k <- dim(mat)[2]
colnames(df) <- c(paste("x", 1:k, sep = ""))
df
}
# Input:
#           df: a data frame to be resampled
#           k: number of resampled datasets to generate.
#           f: a function of df giving the statistic of interest (e.g. function(df) { mean(df$x1) })
#           q: a real number 0 < q < 0.5 giving the lower quantile of the desired confident interval.
# Output:   a four element vector giving the statistic of interest (first element), and lower and upper
#           confidence intervals around it, corresponding to q and 1-q quantiles (second and third elements),
#           and the size of the confidence interval (fourth element).
bootstrap_ci = function(df, k, f, q){
est <- f(df)
mu <- rep(0, k)
for(i in 1:k){
df_r <- df_resample(df)
mu[i] <- f(df_r)
}
mu <- sort(mu)
c(est, est + quantile(est - mu, q, names = FALSE), est + quantile(est - mu, 1-q, names = FALSE),
quantile(est - mu, 1-q, names = FALSE) - quantile(est - mu, q, names = FALSE)
)
}
# Input:
#           a training dataset given as a set of feature rows, represented
#           by a n by k matrix X, and a set of corresponding
#           output predictions, represented by a n by 1 matrix y.
# Output:
#           A row vector of weights for a linear regression model (with an intercept)
#           maximizing the likelihood of observing the data.
linreg = function(X, y){
t(solve(t(X) %*% X) %*% t(X) %*% y)
}
logis = function(x){
1 / (1 + exp(-x))
}
set.seed(0)
k <- 100
df <- ch3_sim_study(n = 500)
x2 <- c(1,2,4,3,7,6,9,10,11)
y2 <- 8
x1 <- c(1,2,4,3,9)
q_features <- c(1,2,4,3,1,6,9,4,5)
a2_features <- c(5,8,9)
df
est <- f(df)
est
function_length <- length(est)
mu <- matrix(nrow = k, ncol = function_length)
for(i in 1:k){
df_r <- df_resample(df)
mu[i,] <- f(df_r)
}
mu <- apply(mu, 2, sort)
mu
apply(est - mu, 2, function(x) quantile(x, 0.025, names = FALSE))
apply(est - mu, 2, function(x) quantile(x, 0.975, names = FALSE))
est
rm(list=ls())
source('~/Desktop/Fall 2020/Causal Inference/homework5/homework5.R')
source('~/Desktop/Fall 2020/Causal Inference/homework5/homework5.R')
source('~/Desktop/Fall 2020/Causal Inference/homework5/homework5.R')
est
set.seed(0)
k <- 100
df <- ch3_sim_study(n = 500)
x2 <- c(1,2,4,3,7,6,9,10,11)
y2 <- 8
x1 <- c(1,2,4,3,9)
q_features <- c(1,2,4,3,1,6,9,4,5)
a2_features <- c(5,8,9)
f <- function(df) q_learning(df, x2, y2, x1, q_features, a2_features)
q = 0.025
est <- f(df)
function_length <- length(est)
mu <- matrix(nrow = k, ncol = function_length)
for(i in 1:k){
df_r <- df_resample(df)
mu[i,] <- f(df_r)
}
mu
apply(mu, 2, sort)
est
est - mu
mu <- apply(mu, 2, sort)
est - mu
mu
est - mu
est[1]
mu[1,]
est - mu[1,]
est
mu
mu[1,]
est - mu
est - mu[2,]
help(rep)
rep(c(1,2,3),4)
t(replicate(2, c(1,2,3)))
replicate(2, c(1,2,3))
t(replicate(k, est))
t(replicate(k, est)) - mu
source('~/Desktop/Fall 2020/Causal Inference/homework5/homework5.R')
est
help("sample")
source('~/.active-rstudio-document')
df
}rm(list=ls())
rm(list=ls())
source('~/.active-rstudio-document')
birthwt
source('~/.active-rstudio-document')
birthwt
source('~/.active-rstudio-document')
install.packages("leaps")
source('~/.active-rstudio-document')
b
source('~/.active-rstudio-document')
rs
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
r
rs
source('~/.active-rstudio-document')
rs
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
rs
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
rs
help("regsubsets")
g <- lm(bwt ~ ., data = birthwt)
summary(g)
g2 <- update(g, . ~ . - age)
summary(g2)
g3 <- update(g2, . ~ . - ftv)
summary(g3)
g4 <- update(g3, . ~ . - ptl)
summary(g4)
data(leukemia)
library(crayon)
library(cran)
353.1808 + 2 * 3.912023
344.9055 + 3 * 3.912023
343.6741 + 4 * 3.912023
343.4756 + 5 * 3.912023
data("iris")
iris
model <- vglm(Species ~ Sepal.Width, family = multinomial, data = iris)
help(vglm)
??vglm
model <- glm(Species ~ Sepal.Width, family = multinomial, data = iris)
library(VGAM)
model <- glm(Species ~ Sepal.Width, family = multinomial, data = iris)
model <- vglm(Species ~ Sepal.Width, family = multinomial, data = iris)
summary(model)
predict(model, newdata = 4, type = "response")
iris
model
iris_copy <- iris
iris_copy$Sepal.Width <- 4
iris_copy
predict(model, newdata = iris_copy, type = "response")
iris_copy
1/(1+exp(0))
1/(1+exp(4*4.0791))
predict(model, newdata = 4, type = "response")
model.type
type(model)
t(model)
predict(model, newdata = 4, type = "response")
predict(model, newdata = iris_copy[1,:], type = "response")
predict(model, newdata = iris_copy[1,], type = "response")
predict(model, newdata = iris_copy[2,], type = "response")
59.09/60.09
59.09/(60.09+0.13)
getwd()
setwd('Desktop/Spring 2021/Applied Stats 2')
setwd('Project/')
data <- read.csv('TRAIN_ver04.csv')
data
library("leaps")
variable_selection <- regsubsets(NMONTHS ~ ., data = data)
variable_selection <- regsubsets(NMONTHS ~ ORIGRATE, data = data)
variable_selection <- regsubsets(NMONTHS ~ ORIGRATE + ORIGUPB, data = data)
variable_selection <- regsubsets(NMONTHS ~ ORIGRATE + ORIGUPB + ORIGTERM, data = data)
variable_selection <- regsubsets(NMONTHS ~ ORIGRATE + ORIGUPB + ORIGTERM + LOANAGE + REMMNTHS + OLTV + NUMBO, data = data)
help("regsubsets")
variable_selection <- regsubsets(NMONTHS ~ ORIGRATE + ORIGUPB + ORIGTERM + LOANAGE + REMMNTHS + OLTV + NUMBO, data = data, nvmax = 6)
variable_selection <- regsubsets(NMONTHS ~ ORIGRATE + ORIGUPB + ORIGTERM + LOANAGE + REMMNTHS + OLTV + NUMBO, data = data, nvmax = 5)
variable_selection <- regsubsets(NMONTHS ~ ORIGRATE + ORIGUPB + ORIGTERM + LOANAGE + REMMNTHS + OLTV + NUMBO, data = data, nvmax = 3)
variable_selection <- regsubsets(NMONTHS ~ ORIGRATE + ORIGUPB + ORIGTERM + LOANAGE + REMMNTHS + OLTV + NUMBO, data = data, nvmax = 2)
variable_selection <- regsubsets(NMONTHS ~ ORIGRATE + ORIGUPB + ORIGTERM + LOANAGE + REMMNTHS + OLTV + NUMBO, data = data, nvmax = 1
)
variable_selection <- regsubsets(NMONTHS ~ ORIGRATE + ORIGUPB + ORIGTERM + LOANAGE + REMMNTHS + OLTV, data = data)
variable_selection <- regsubsets(NMONTHS ~ ORIGRATE + ORIGUPB + ORIGTERM + LOANAGE + REMMNTHS, data = data)
variable_selection <- regsubsets(NMONTHS ~ ORIGRATE + ORIGUPB + ORIGTERM + LOANAGE, data = data)
View(data)
View(data)
variable_selection <- regsubsets(NMONTHS ~ ORIGRATE + ORIGUPB + ORIGTERM + LOANAGE + ADJRMTHS, data = data)
variable_selection <- regsubsets(NMONTHS ~ ORIGRATE + ORIGUPB + ORIGTERM + LOANAGE + ADJRMTHS + OLTV, data = data)
variable_selection <- regsubsets(NMONTHS ~ ORIGRATE + ORIGUPB + ORIGTERM + LOANAGE + ADJRMTHS + OLTV + NUMBO, data = data)
variable_selection <- regsubsets(NMONTHS ~ ORIGRATE + ORIGUPB + ORIGTERM + LOANAGE + ADJRMTHS + OLTV + NUMBO + DTI, data = data)
variable_selection <- regsubsets(NMONTHS ~ ORIGRATE + ORIGUPB + ORIGTERM + LOANAGE + ADJRMTHS + OLTV + NUMBO + DTI + CSCOREB, data = data)
variable_selection <- regsubsets(NMONTHS ~ ORIGRATE + ORIGUPB + ORIGTERM + LOANAGE + ADJRMTHS + OLTV + NUMBO + DTI + CSCOREB+ DLQSTATUS, data = data)
variable_selection <- regsubsets(NMONTHS ~ ORIGRATE + ORIGUPB + ORIGTERM + LOANAGE + ADJRMTHS + OLTV + NUMBO + DTI + CSCOREB+ DLQSTATUS + ACTPER_MO, data = data)
variable_selection <- regsubsets(NMONTHS ~ ORIGRATE + ORIGUPB + ORIGTERM + LOANAGE + ADJRMTHS + OLTV + NUMBO + DTI + CSCOREB+ DLQSTATUS + ACTPER_MO + TIMGAP1, data = data)
variable_selection <- regsubsets(NMONTHS ~ ORIGRATE + ORIGUPB + ORIGTERM + LOANAGE + ADJRMTHS + OLTV + NUMBO + DTI + CSCOREB+ DLQSTATUS + ACTPER_MO + TIMGAP1 + TIMGAP2, data = data)
model <- lm(NMONTHS ~ . - LID - REMMNTHS - TIMGAP2 - FORCLOSED, data = data)
model <- lm(NMONTHS ~ . - LID - REMMNTHS - FORCLOSED, data = data)
model <- lm(NMONTHS ~ . - LID - FORCLOSED, data = data)
model$coefficients
summary(model)
model <- lm(NMONTHS ~ . - LID - REMMNTHS - TIMGAP2 - FORCLOSED, data = data)
summary(model)
summary(model)$coefficients
summary(model)$coefficients[4,]
summary(model)$coefficients[,4]
summary(model)
help(stepAIC)
library(MASS)
help(stepAIC)
help(stepBIC)
stepAIC(lm(NMONTHS ~ . - LID - REMMNTHS - TIMGAP2 - FORCLOSED, data = data),scope=NMONTHS~.,direction="backward")
full_model <- lm(NMONTHS ~ . - LID - REMMNTHS - TIMGAP2 - FORCLOSED, data = data)
step(full_model, direction = "both")
help("step")
length(data)
width(data)
nrow(data)
number_rows <- nrow(data)
BIC_model <- step(full_model, direction = "both", k = log(number_rows))
full_model$adjr2
summary(full_model)
summary(full_model)$adjr2
summary(full_model)
summary(full_model)$adj.r.squared
names(full_model)
names(full_model)[-1]
full_model$coefficients
names(full_model$coefficients)
summary(BIC_model)
names(data)
names(data) - "LID"
variables <- name(data)
variables <- names(data)
variables
variables[1] = NULL
variables[1] <- NULL
variables[1]
variables[-1]
variables <- variables[-1]
variables
variables <- variables[-7]
variables
variables <- variables[1:22]
variables
variables <- names(data)
variables <- variables[-1]
variables <- variables[-7]
variables <- variables[1:22]
variables
listOfModels <- vector("list", length(variables))
listOfModels
listOfModels <- vector("list", length(variables))
# loop over features
for (i in seq_along(variables)) {
# exclude feature i
currentFeatures <- variables[-i]
# programmatically assemble regression formula
regressionFormula <- as.formula(
paste("NMONTHS ~ ", paste(currentFeatures, collapse="+")))
# fit model
currentModel <- lm(formula = regressionFormula, data = d)
# store model in container
listOfModels[[i]] <- currentModel
}
listOfModels <- vector("list", length(variables))
# loop over features
for (i in seq_along(variables)) {
# exclude feature i
currentFeatures <- variables[-i]
# programmatically assemble regression formula
regressionFormula <- as.formula(
paste("NMONTHS ~ ", paste(currentFeatures, collapse="+")))
# fit model
currentModel <- lm(formula = regressionFormula, data = data)
# store model in container
listOfModels[[i]] <- currentModel
}
listOfModels
source('~/.active-rstudio-document')
updated_variables
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
updated_variables
source('~/.active-rstudio-document')
updated_variables
source('~/Desktop/Spring 2021/Applied Stats 2/Project/Backward Elimination.R')
updated_variables
variables
variables <- names(data)
variables <- variables[-1]
variables <- variables[-7]
variables <- variables[1:22]
variables <- variables[-7]
listOfModels <- vector("list", length(variables))
# loop over features
updated_r_squared <- summary(full_model)$adj.r.squared
updated_variables <- variables
repeat {
original_r_squared <- updated_r_squared
variables <- updated_variables
for (i in seq_along(variables)) {
# exclude feature i
currentFeatures <- variables[-i]
# programmatically assemble regression formula
regressionFormula <- as.formula(
paste("NMONTHS ~ ", paste(currentFeatures, collapse="+")))
# fit model
currentModel <- lm(formula = regressionFormula, data = data)
# store model in container
if (summary(currentModel)$adj.r.squared > updated_r_squared) {
updated_variables <- currentFeatures
updated_r_squared <- summary(currentModel)$adj.r.squared
}
}
if (updated_r_squared == original_r_squared) {
break
}
}
updated_variables
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
summary(full_model)
help("regsubsets")
source('~/.active-rstudio-document')
summary(full_model)
updated_r_squared
updated_variables
source('~/.active-rstudio-document')
rs
<-
summary
(
full_model
)
rs
<-
summary
(
full_model
)
rs
full_model;
full_model
summary(full_model)
plot(2:13, n * log(rs$rss/n) + 2 * (2:13), xlab = "Number of predictor (including intercept)", ylab = "AIC")
n <- nrows(data)
n <- nrow(data)
plot(2:13, n * log(rs$rss/n) + 2 * (2:13), xlab = "Number of predictor (including intercept)", ylab = "AIC")
plot(2:13, n * log(rs$rss/n) + 2 * (2:13), xlab = "Number of predictor (including intercept)", ylab = "AIC", title = "AIC of the best models given the number of predictors")
plot(2:13, n * log(rs$rss/n) + 2 * (2:13), xlab = "Number of predictor (including intercept)", ylab = "AIC", title(AIC of the best models given the number of predictors))
plot(2:13, n * log(rs$rss/n) + log(n) * (2:13), xlab = "Number of predictor (including intercept)", ylab = "BIC")
n
plot(2:13, n * log(rs$rss/n) + 2 * (2:13), xlab = "Number of predictor (including intercept)", ylab = "AIC")
n * log(rs$rss/n) + 2 * (2:13)
rs
rs <- summary(full_model)
rs
plot(2:13, n * log(rs$rss/n) + 2 * (2:13), xlab = "Number of predictor (including intercept)", ylab = "AIC")
plot(2:13, n * log(rs$rss/n) + log(n) * (2:13), xlab = "Number of predictor (including intercept)", ylab = "BIC")
plot(2:13, n * log(rs$rss/n) + 2 * (2:13), xlab = "Number of predictor (including intercept)", ylab = "AIC")
plot(2:13, n * log(rs$rss/n) + log(n) * (2:13), xlab = "Number of predictor (including intercept)", ylab = "BIC")
plot(2:13, rs$adjr2, xlab = "Number of predictor (including intercept)", ylab = "Adjusted R-squared")
plot(2:13, rs$cp, xlab = "Number of predictor (including intercept)", ylab = "Mallow's Cp)
plot(2:13, rs$cp, xlab = "Number of predictor (including intercept)", ylab = "Mallow's Cp")
abline(0,1)
help("regsubsets")
